{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSC 630/1 Zufelt <br>\n",
    "Michelle Chao, Sam Xifaras, Darius Lam, Moe Sunami, Diva Harsoor\n",
    "\n",
    "# Catalog Card Processing\n",
    "Creating a training dataset for object character recognition in order to read catalog cards (Robert S. Peabody Museum of Archaeology, 1930s to 1970s)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given scanned PDFs of typewritten catalog cards, our goal is to create a dataset in which each row is a set of images of each character in a card.<br> <br>\n",
    "Tasks: \n",
    "<ul>\n",
    "    <li>Convert PDFs to TIFFs</li>\n",
    "    <li>Cut the images into different sections corresponding to data type </li>\n",
    "    <li>Cut the images into characters and add each image as a row of a DataFrame </li>\n",
    "    <li>Label the DataFrame with the proper character labels</li>\n",
    "    <li>Write a script that presents a user with a randomly generated row/image and its corresponding label (to check for accuracy)</li>\n",
    "    <li>Display the process in this Jupyter Notebook</li>\n",
    "</ul>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "import cv2 #used for Otsu's Thresholding\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage import segmentation\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below make calls to the following script, `util.sh`, which performs two important functions. First, the `merge` function, meant to be performed only once, moves all of the pdfs from their respective Acc. No. directories to the parent directory, `Accession Files`. This was more for convenience, because dealing with file names with spaces in bash is a hassle, and the accession numbers are indicated in the filenames, so we aren't losing any information when doing this.\n",
    "\n",
    "Here is the code:\n",
    "   \n",
    "```\n",
    "# util.sh\n",
    "\n",
    "if [ \"$1\" == \"merge\" ]\n",
    "then\n",
    "    pushd \"$2\"\n",
    "    for f in *\n",
    "    do\n",
    "        echo \"Moving files from $f\"\n",
    "        pushd \"$f\"\n",
    "        cp * ../ -fpv\n",
    "        popd\n",
    "        \n",
    "        echo \"Removing $f\"\n",
    "        rm \"$f\" -fR\n",
    "    done \n",
    "    popd\n",
    "\n",
    "elif [ \"$1\" == \"convert\" ]\n",
    "then\n",
    "\n",
    "    ACCNO=$2\n",
    "    CATNO=$3\n",
    "\n",
    "    # This is the path to the peabody_files directory\n",
    "    ROOT=$4\n",
    "\n",
    "    # Path to the ghostscript executable\n",
    "    GS=$5\n",
    "\n",
    "    pushd \"${ROOT}\"\n",
    "\n",
    "    \"$GS\" -dNOPAUSE -r300 -sDEVICE=tiffscaled24 -sCompression=lzw -dBATCH -sOutputFile=${ACCNO}_${CATNO}.tif ${ACCNO}_${CATNO}.pdf\n",
    "\n",
    "    popd\n",
    "\n",
    "fi \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge(acc_files_dir='peabody_files/Accession Files'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Moves all the pdfs to the parent directory, so that all the pdfs are in one directory, \n",
    "    and deletes all the 'Acc. No.' directories.\n",
    "    \"\"\"\n",
    "    return subprocess.call([\"sh\", \"util.sh\", \"merge\", acc_files_dir])\n",
    "\n",
    "def convert(acc_no, cat_no, gs_exec, acc_files_dir='peabody_files/Accession Files'):\n",
    "\n",
    "    # Convert a specified pdf to tif\n",
    "    subprocess.call([\"sh\", \"util.sh\", \"convert\", str(acc_no), str(cat_no).zfill(4), acc_files_dir, gs_exec])\n",
    "    \n",
    "    FNAME = str(acc_no) + '_' + str(cat_no).zfill(4)\n",
    "    # Open the tif as a pillow object, delete the tif file, and return it\n",
    "    \n",
    "    tif = Image.open(acc_files_dir + '/' + FNAME + '.tif')\n",
    "    \n",
    "    subprocess.call(['rm', FNAME + '.tif'])\n",
    "    \n",
    "    return tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this if the pdfs are still organized into their respective directories.\n",
    "# merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example of opening an image\n",
    "img = convert(1, 2, 'C:/Program Files/gs/gs9.20/bin/gswin64c.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "We decided to use Otsu's Thresholding to binarize the image into only black and white pixels. It searches for the threshold that minimizes interclass variance - the class here are black pixels and white classes. It determines the threshold with a weighted probability; then, it assigns all the pixels over the threshold the value `1` and all those below the value `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the OpenCV module to apply Otsu's Thresholding method on the images. The following command allowed us to install OpenCV:\n",
    "* conda install --channel https://conda.anaconda.org/menpo opencv3\n",
    "\n",
    "\n",
    "\n",
    "These cells apply Otsu's Thresholding method to binarize the images, which are saved in a new folder called `peabody_files_otsu`. (folder is on Google Drive).\n",
    "Afterwards, we use the Scikit-Image library to crop the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "from skimage import io\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def otsu_threshold(im_path):\n",
    "    im = Image.open(im_path)\n",
    "    im = cv2.cvtColor(np.array(im),cv2.COLOR_RGB2GRAY)\n",
    "    im = im[10:im.shape[0]-10,10:im.shape[1]-10]\n",
    "    height,width = im.shape\n",
    "    t, d = cv2.threshold(im,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_nums = ['1','2','3','4','5','6','7','16','17','18','20','21','22','23','24','25']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two cells create the new folder containing the binarized images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_folder = (\"peabody_files_otsu\")\n",
    "os.mkdir(save_folder)\n",
    "os.mkdir(\"peabody_files_otsu/Accession_Files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootdir = 'peabody_files/Accession_Files'\n",
    "\n",
    "for acc_no in acc_nums:\n",
    "    ## Creates new folder to save files in\n",
    "    new_folder_path = \"peabody_files_otsu/Accession_Files/Acc._No._\" + str(acc_no)\n",
    "    os.mkdir(new_folder_path)\n",
    "    \n",
    "    ## Finding image\n",
    "    path = rootdir + \"/Acc._No._\" + str(acc_no)\n",
    "    for file,subdir,filelist in os.walk(path):\n",
    "        for image_name in filelist:\n",
    "            image_path = path + \"/\" + image_name\n",
    "            image_save_name = image_name + \".png\"\n",
    "            save_path = new_folder_path + \"/\" + image_save_name\n",
    "            cv2.imwrite(save_path,otsu_threshold(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "We have a few different ideas about how to separate out each character. Some of those processes work better with only one line of text (rather than text that wraps) and will interpret the black section boxes as individual characters. For ease down the line, we decided to store each card as a dictionary of section names and the cropped image of the corresponding data. <br><br>\n",
    "In the next cells we use skimage to crop the binarized images, and save these pieces into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_image(sk_im):\n",
    "    'Takes a skimage image file and crops the image, returns a dictionary of the pieces.'\n",
    "    pieces = {}\n",
    "    left_box = sk_im[5:600,5:420]\n",
    "    length,height = left_box.shape[1],int(left_box.shape[0]/4)\n",
    "    left_box_pieces = [left_box[i*height-height:i*height,0:length] for i in range(1,5)]\n",
    "    \n",
    "    right_box = sk_im[5:600,470:1770]\n",
    "    length,height = right_box.shape[1], int(right_box.shape[0]/4)\n",
    "    right_box_pieces = [right_box[i*height-height:i*height,0:length] for i in range(1,5)]\n",
    "    \n",
    "    bottom_box = sk_im[620:1100,10:1775]\n",
    "    length,height = bottom_box.shape[1],int(bottom_box.shape[0]/4)\n",
    "    bottom_box_pieces = [bottom_box[i*height-height:i*height,0:length] for i in range(1,4)]\n",
    "    \n",
    "    names = ['cat_no','acc_no','orig_no','photo_no']\n",
    "    pieces.update(dict(zip(names,left_box_pieces)))\n",
    "    \n",
    "    names = ['name','site','site_no','locality']\n",
    "    pieces.update(dict(zip(names,right_box_pieces)))\n",
    "    \n",
    "    names = ['situation','remarks','figured']\n",
    "    pieces.update(dict(zip(names,bottom_box_pieces)))\n",
    "    \n",
    "    return pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootdir = 'peabody_files_otsu/Accession_Files'\n",
    "filed_dict = {} ## each key contains an array of the dictionaries of cropped images\n",
    "total_array = [] ## contains all dictionaries of cropped images, not filed\n",
    "for acc_no in acc_nums:\n",
    "    path = rootdir + \"/Acc._No._\" + str(acc_no)\n",
    "    folder = []\n",
    "    for file,subdir,filelist in os.walk(path):\n",
    "        for image_name in filelist:\n",
    "            image_path = path + \"/\" + image_name\n",
    "            image = io.imread(image_path)\n",
    "            ### if you want `folder` to be a dictionary with keys of image names eg. key = 1_0016\n",
    "            \n",
    "            # folder = {} \n",
    "            # folder[re.sub(\"[\\w.]\",\"\",image_name)] = crop_image(image)\n",
    "            \n",
    "            ### otherwise folder is an array\n",
    "            \n",
    "            folder.append(crop_image(image)) \n",
    "            \n",
    "    total_array.append(folder)\n",
    "    filed_dict[acc_no] = folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell goes through all of the binarized images in each accession-number folder. In each accession-number folder, all of the images are cropped by the labels on the images. The pieces of these images can be accessed through a dictionary, where the keys are the labels on the image. There is one dictionary per image. Then, the dictionaries for each image under an accession number are added into an array. This array can be accessed through the dictionary called `filed_dict`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see the piece containing `name` in the first image in the Accession No. 1 folder, for example, we can use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "io.imshow(filed_dict['1'][0]['name'],cmap='gray',vmin=0,vmax=225)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = plt.imread('test.png')\n",
    "plt.imshow(image,cmap=plt.cm.gray)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg = segmentation.felzenszwalb(image,scale=5,sigma=.25,min_size=50)\n",
    "plt.imshow(seg)\n",
    "print(np.max(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bbox2(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "for i in range(72):\n",
    "    x1,x2,y1,y2 = bbox2(seg==i)\n",
    "    plt.figure(i)\n",
    "    plt.imshow(image[x1:x2,y1:y2],cmap=plt.cm.gray)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
